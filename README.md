# FedIDS
## Privacy-Preserving Personalized Federated Learning for Intrusion Detection Systems

## ğŸ“Œ Overview

**FedIDS** is a research-oriented Federated Learning (FL) framework designed for **Network Intrusion Detection Systems (NIDS)** that enables collaborative model training across multiple clients **without sharing raw network traffic data**.

The framework combines:
- **Federated Averaging (FedAvg)** as a baseline
- **Personalized Federated Learning (PFL)** for handling data heterogeneity
- **Differential Privacy (DP)** for formal privacy guarantees

FedIDS specifically addresses two critical real-world challenges in cybersecurity:
1. **Non-IID data distributions across organizations**
2. **Strict privacy requirements on sensitive network traffic**

This repository contains the **complete, frozen, and reproducible implementation** used for experimental evaluation and research publication.

---

## ğŸ¯ Key Contributions

- Personalized Federated Learning architecture robust to **Non-IID client data**
- Differential Privacy with configurable **privacy budget (Îµ)**
- Extensive evaluation on **NSL-KDD** and **CICIDS2017** datasets
- Privacyâ€“utility tradeoff analysis
- Communication-efficient training (~70 KB per client per round in PFL)
- Stable convergence under heterogeneous and privacy-constrained settings

---

## ğŸ—ï¸ Project Structure

```

FedIDS-Project/
â”œâ”€â”€ main.py
â”œâ”€â”€ personalized_fl.py
â”œâ”€â”€ federated_server.py
â”œâ”€â”€ federated_client.py
â”œâ”€â”€ preprocessing.py
â”œâ”€â”€ privacy.py
â”œâ”€â”€ metrics.py
â”œâ”€â”€ generate_graphs.py
â”œâ”€â”€ results/
â”œâ”€â”€ graphs/
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md

---

## ğŸ§ª Experimental Design

### Learning Paradigms
- Federated Averaging (FedAvg)
- Personalized Federated Learning (PFL)

### Data Distributions
- IID
- Non-IID (label-skewed client partitions)

### Privacy Budgets
- Îµ = 0 (No Differential Privacy)
- Îµ = 1
- Îµ = 2
- Îµ = 5

### Evaluation Metrics
- Accuracy
- Macro F1-score
- False Positive Rate (FPR)
- Convergence Stability
- Communication Cost
- Median Inference Latency
- Privacyâ€“Utility Tradeoff

---

## ğŸ“Š Key Findings

- FedAvg performs well only under IID and non-private settings
- FedAvg becomes unstable under Non-IID data and strong privacy constraints
- PFL maintains stable convergence under Non-IID data
- PFL exhibits a more graceful privacyâ€“utility tradeoff
- Communication overhead in PFL remains nearly constant across Îµ values
- Differential Privacy reduces false positives by acting as regularization

---

## âš™ï¸ Installation

```bash
pip install -r requirements.txt

---

## â–¶ï¸ Running Experiments

```bash
python main.py --rounds 20 --epsilon 0 --iid
python main.py --rounds 20 --epsilon 2 --noniid
python personalized_fl.py --rounds 20 --epsilon 1 --iid
python personalized_fl.py --rounds 20 --epsilon 5 --noniid
```

---

## ğŸ“ˆ Generate Figures

```bash
python generate_graphs.py
```

Graphs are saved in the `graphs/` directory.

---

## ğŸ” Reproducibility Notes

* Dependency versions are locked
* Datasets are not included due to licensing
* Results correspond exactly to the paper experiments
* Repository is version-tagged for reproducibility

---

## ğŸ“„ License

Academic and research use only.

---

## Contact

**Author:** Chinmay Patil
**Domain:** Federated Learning Â· Privacy-Preserving ML Â· Cybersecurity

